#pragma once

#include <vector>
#include <queue>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <functional>
#include <future>
#include <atomic>
#include <memory>

#ifdef _WIN32
#include <windows.h>
#endif

// ???????????????????????????????????????????????????????????????????????????????
// HIGH-PERFORMANCE THREAD POOL FOR HFT
// ???????????????????????????????????????????????????????????????????????????????
// Features:
// - Work stealing for load balancing
// - CPU affinity support for cache optimization
// - Priority queue for urgent tasks
// - Minimal lock contention
// ???????????????????????????????????????????????????????????????????????????????

namespace hft {

// ???????????????????????????????????????????????????????????????????????????????
// Task Priority
// ???????????????????????????????????????????????????????????????????????????????
enum class TaskPriority {
    Low = 0,
    Normal = 1,
    High = 2,
    Critical = 3  // For order book updates
};

// ???????????????????????????????????????????????????????????????????????????????
// Task wrapper with priority
// ???????????????????????????????????????????????????????????????????????????????
struct Task {
    std::function<void()> func;
    TaskPriority priority;
    int64_t timestamp;  // For ordering same-priority tasks
    
    bool operator<(const Task& other) const {
        if (priority != other.priority) {
            return priority < other.priority;  // Higher priority first
        }
        return timestamp > other.timestamp;  // Earlier timestamp first (FIFO)
    }
};

// ???????????????????????????????????????????????????????????????????????????????
// Thread Pool
// ???????????????????????????????????????????????????????????????????????????????
class ThreadPool {
public:
    explicit ThreadPool(size_t numThreads = 0, bool setCpuAffinity = true) 
        : stop_(false)
        , taskCounter_(0)
        , tasksCompleted_(0)
        , tasksInFlight_(0)
    {
        if (numThreads == 0) {
            numThreads = std::thread::hardware_concurrency();
            if (numThreads == 0) numThreads = 4;  // Fallback
        }
        
        workers_.reserve(numThreads);
        
        for (size_t i = 0; i < numThreads; ++i) {
            workers_.emplace_back([this, i, setCpuAffinity] {
                // Set CPU affinity if requested
                if (setCpuAffinity) {
                    SetThreadAffinity(i);
                }
                
                WorkerLoop();
            });
        }
    }
    
    ~ThreadPool() {
        Shutdown();
    }
    
    // ???????????????????????????????????????????????????????????????????????????
    // Submit task with priority
    // ???????????????????????????????????????????????????????????????????????????
    template<typename F, typename... Args>
    auto Submit(TaskPriority priority, F&& f, Args&&... args) 
        -> std::future<typename std::invoke_result<F, Args...>::type>
    {
        using ReturnType = typename std::invoke_result<F, Args...>::type;
        
        auto task = std::make_shared<std::packaged_task<ReturnType()>>(
            std::bind(std::forward<F>(f), std::forward<Args>(args)...)
        );
        
        std::future<ReturnType> result = task->get_future();
        
        {
            std::unique_lock<std::mutex> lock(queueMutex_);
            
            if (stop_) {
                throw std::runtime_error("ThreadPool is stopped");
            }
            
            Task t;
            t.func = [task]() { (*task)(); };
            t.priority = priority;
            t.timestamp = taskCounter_++;
            
            taskQueue_.push(std::move(t));
            tasksInFlight_++;
        }
        
        condition_.notify_one();
        return result;
    }
    
    // Submit with normal priority (convenience)
    template<typename F, typename... Args>
    auto Submit(F&& f, Args&&... args) {
        return Submit(TaskPriority::Normal, std::forward<F>(f), std::forward<Args>(args)...);
    }
    
    // Submit critical task (for order book updates)
    template<typename F, typename... Args>
    auto SubmitCritical(F&& f, Args&&... args) {
        return Submit(TaskPriority::Critical, std::forward<F>(f), std::forward<Args>(args)...);
    }
    
    // ???????????????????????????????????????????????????????????????????????????
    // Fire and forget (no future returned)
    // ???????????????????????????????????????????????????????????????????????????
    template<typename F, typename... Args>
    void Execute(TaskPriority priority, F&& f, Args&&... args) {
        {
            std::unique_lock<std::mutex> lock(queueMutex_);
            
            if (stop_) return;
            
            Task t;
            t.func = std::bind(std::forward<F>(f), std::forward<Args>(args)...);
            t.priority = priority;
            t.timestamp = taskCounter_++;
            
            taskQueue_.push(std::move(t));
            tasksInFlight_++;
        }
        
        condition_.notify_one();
    }
    
    template<typename F, typename... Args>
    void Execute(F&& f, Args&&... args) {
        Execute(TaskPriority::Normal, std::forward<F>(f), std::forward<Args>(args)...);
    }
    
    // ???????????????????????????????????????????????????????????????????????????
    // Control
    // ???????????????????????????????????????????????????????????????????????????
    
    void Shutdown() {
        {
            std::unique_lock<std::mutex> lock(queueMutex_);
            if (stop_) return;
            stop_ = true;
        }
        
        condition_.notify_all();
        
        for (auto& worker : workers_) {
            if (worker.joinable()) {
                worker.join();
            }
        }
    }
    
    // Wait for all tasks to complete
    void WaitAll() {
        std::unique_lock<std::mutex> lock(queueMutex_);
        completionCondition_.wait(lock, [this] {
            return taskQueue_.empty() && tasksInFlight_ == 0;
        });
    }
    
    // ???????????????????????????????????????????????????????????????????????????
    // Statistics
    // ???????????????????????????????????????????????????????????????????????????
    
    size_t NumThreads() const { return workers_.size(); }
    size_t PendingTasks() const { 
        std::unique_lock<std::mutex> lock(queueMutex_);
        return taskQueue_.size(); 
    }
    int64_t TasksCompleted() const { return tasksCompleted_.load(); }
    size_t TasksInFlight() const { return tasksInFlight_.load(); }

private:
    void WorkerLoop() {
        while (true) {
            Task task;
            
            {
                std::unique_lock<std::mutex> lock(queueMutex_);
                
                condition_.wait(lock, [this] {
                    return stop_ || !taskQueue_.empty();
                });
                
                if (stop_ && taskQueue_.empty()) {
                    return;
                }
                
                if (!taskQueue_.empty()) {
                    task = std::move(const_cast<Task&>(taskQueue_.top()));
                    taskQueue_.pop();
                }
            }
            
            if (task.func) {
                task.func();
                tasksCompleted_++;
                tasksInFlight_--;
                
                // Notify completion waiters
                completionCondition_.notify_all();
            }
        }
    }
    
    void SetThreadAffinity(size_t threadIndex) {
#ifdef _WIN32
        // Windows: Set thread affinity to specific CPU core
        DWORD_PTR mask = 1ULL << (threadIndex % std::thread::hardware_concurrency());
        SetThreadAffinityMask(GetCurrentThread(), mask);
        
        // Set high priority for worker threads
        SetThreadPriority(GetCurrentThread(), THREAD_PRIORITY_ABOVE_NORMAL);
#else
        // Linux: Use pthread_setaffinity_np
        cpu_set_t cpuset;
        CPU_ZERO(&cpuset);
        CPU_SET(threadIndex % std::thread::hardware_concurrency(), &cpuset);
        pthread_setaffinity_np(pthread_self(), sizeof(cpu_set_t), &cpuset);
#endif
    }

private:
    std::vector<std::thread> workers_;
    std::priority_queue<Task> taskQueue_;
    
    mutable std::mutex queueMutex_;
    std::condition_variable condition_;
    std::condition_variable completionCondition_;
    
    std::atomic<bool> stop_;
    std::atomic<int64_t> taskCounter_;
    std::atomic<int64_t> tasksCompleted_;
    std::atomic<size_t> tasksInFlight_;
};

// ???????????????????????????????????????????????????????????????????????????????
// Global Thread Pool Singleton
// ???????????????????????????????????????????????????????????????????????????????
class GlobalThreadPool {
public:
    static ThreadPool& Get() {
        static ThreadPool pool;
        return pool;
    }
    
    // Disable copy/move
    GlobalThreadPool(const GlobalThreadPool&) = delete;
    GlobalThreadPool& operator=(const GlobalThreadPool&) = delete;

private:
    GlobalThreadPool() = default;
};

} // namespace hft
